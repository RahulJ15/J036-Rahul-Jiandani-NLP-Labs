{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9243600,"sourceType":"datasetVersion","datasetId":5591651},{"sourceId":9287411,"sourceType":"datasetVersion","datasetId":5622139}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom gensim.models import Word2Vec\nfrom nltk.tokenize import word_tokenize\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T10:08:19.375588Z","iopub.execute_input":"2024-08-31T10:08:19.375861Z","iopub.status.idle":"2024-08-31T10:08:33.851435Z","shell.execute_reply.started":"2024-08-31T10:08:19.375830Z","shell.execute_reply":"2024-08-31T10:08:33.850402Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset/IMDB Dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:08:33.853048Z","iopub.execute_input":"2024-08-31T10:08:33.853580Z","iopub.status.idle":"2024-08-31T10:08:35.555894Z","shell.execute_reply.started":"2024-08-31T10:08:33.853543Z","shell.execute_reply":"2024-08-31T10:08:35.554615Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\nfrom nltk.corpus import stopwords\n\n# Ensure you have the stopwords downloaded\nimport nltk\n# 1. Text Cleaning\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    text = text.lower()\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = re.sub(r'\\d+', '', text)\n    text = ' '.join(word for word in text.split() if word not in stop_words)\n    text = text.strip()\n    return text\n\ndf['cleaned_text'] = df['review'].apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:08:39.484594Z","iopub.execute_input":"2024-08-31T10:08:39.485233Z","iopub.status.idle":"2024-08-31T10:08:45.265673Z","shell.execute_reply.started":"2024-08-31T10:08:39.485196Z","shell.execute_reply":"2024-08-31T10:08:45.264868Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:08:45.267133Z","iopub.execute_input":"2024-08-31T10:08:45.267461Z","iopub.status.idle":"2024-08-31T10:08:45.307624Z","shell.execute_reply.started":"2024-08-31T10:08:45.267429Z","shell.execute_reply":"2024-08-31T10:08:45.306927Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:08:46.615075Z","iopub.execute_input":"2024-08-31T10:08:46.615502Z","iopub.status.idle":"2024-08-31T10:08:46.635119Z","shell.execute_reply.started":"2024-08-31T10:08:46.615465Z","shell.execute_reply":"2024-08-31T10:08:46.634248Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 4. Frequency-Based Vectors (CountVectorizer)\n\nvectorizer = CountVectorizer()\nX_train_counts = vectorizer.fit_transform(train_df['cleaned_text'])\nX_test_counts = vectorizer.transform(test_df['cleaned_text'])","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:08:52.563298Z","iopub.execute_input":"2024-08-31T10:08:52.564401Z","iopub.status.idle":"2024-08-31T10:08:59.824151Z","shell.execute_reply.started":"2024-08-31T10:08:52.564346Z","shell.execute_reply":"2024-08-31T10:08:59.823135Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 5. Word Vectors (Word2Vec)\ntokenized_corpus = [word_tokenize(text) for text in train_df['cleaned_text']]\nw2v_model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\nw2v_model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:08:59.826060Z","iopub.execute_input":"2024-08-31T10:08:59.826442Z","iopub.status.idle":"2024-08-31T10:10:54.397019Z","shell.execute_reply.started":"2024-08-31T10:08:59.826397Z","shell.execute_reply":"2024-08-31T10:10:54.396087Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(46375153, 48637980)"},"metadata":{}}]},{"cell_type":"code","source":"# Function to convert a text to a Word2Vec vector\ndef text_to_w2v(text, model, vector_size):\n    words = word_tokenize(text)\n    word_vecs = [model.wv[word] for word in words if word in model.wv]\n    if len(word_vecs) == 0:\n        return torch.zeros(vector_size)\n    return torch.tensor(sum(word_vecs) / len(word_vecs))\n\ntrain_w2v = torch.stack([text_to_w2v(text, w2v_model, 100) for text in train_df['cleaned_text']])\ntest_w2v = torch.stack([text_to_w2v(text, w2v_model, 100) for text in test_df['cleaned_text']])","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:11:34.113440Z","iopub.execute_input":"2024-08-31T10:11:34.113825Z","iopub.status.idle":"2024-08-31T10:12:58.934449Z","shell.execute_reply.started":"2024-08-31T10:11:34.113791Z","shell.execute_reply":"2024-08-31T10:12:58.933173Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# 6. Custom Dataset for DataLoader\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]\n\ntrain_dataset = TextDataset(train_w2v, torch.tensor(train_df['label'].values))\ntest_dataset = TextDataset(test_w2v, torch.tensor(test_df['label'].values))\n\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:13:29.718096Z","iopub.execute_input":"2024-08-31T10:13:29.718520Z","iopub.status.idle":"2024-08-31T10:13:29.728646Z","shell.execute_reply.started":"2024-08-31T10:13:29.718481Z","shell.execute_reply":"2024-08-31T10:13:29.727424Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# 7. RNN Model and Word2vec in PyTorch\nclass RNNModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n        super(RNNModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        out, _ = self.rnn(x.unsqueeze(1), h0)\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Initialize model, criterion, and optimizer\ninput_size = 100  # Same as Word2Vec vector size\nhidden_size = 50\noutput_size = 2  # Binary classification\n\nmodel = RNNModel(input_size, hidden_size, output_size)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:13:32.867160Z","iopub.execute_input":"2024-08-31T10:13:32.868041Z","iopub.status.idle":"2024-08-31T10:13:33.675942Z","shell.execute_reply.started":"2024-08-31T10:13:32.867988Z","shell.execute_reply":"2024-08-31T10:13:33.674700Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# 8. Training Loop\ndef train_model(model, train_loader, criterion, optimizer, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs.float())\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:13:34.643502Z","iopub.execute_input":"2024-08-31T10:13:34.644096Z","iopub.status.idle":"2024-08-31T10:13:34.650582Z","shell.execute_reply.started":"2024-08-31T10:13:34.644061Z","shell.execute_reply":"2024-08-31T10:13:34.649401Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# 9. Testing Loop\ndef test_model(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            outputs = model(inputs.float())\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:13:35.976801Z","iopub.execute_input":"2024-08-31T10:13:35.977595Z","iopub.status.idle":"2024-08-31T10:13:35.983826Z","shell.execute_reply.started":"2024-08-31T10:13:35.977548Z","shell.execute_reply":"2024-08-31T10:13:35.982876Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Train and test the model\ntrain_model(model, train_loader, criterion, optimizer, epochs=15)\ntest_model(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T10:13:37.313450Z","iopub.execute_input":"2024-08-31T10:13:37.313841Z","iopub.status.idle":"2024-08-31T10:21:29.898324Z","shell.execute_reply.started":"2024-08-31T10:13:37.313804Z","shell.execute_reply":"2024-08-31T10:21:29.897307Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch [1/15], Loss: 0.3326\nEpoch [2/15], Loss: 0.3189\nEpoch [3/15], Loss: 0.3146\nEpoch [4/15], Loss: 0.3100\nEpoch [5/15], Loss: 0.3065\nEpoch [6/15], Loss: 0.3031\nEpoch [7/15], Loss: 0.3008\nEpoch [8/15], Loss: 0.2989\nEpoch [9/15], Loss: 0.2979\nEpoch [10/15], Loss: 0.2958\nEpoch [11/15], Loss: 0.2946\nEpoch [12/15], Loss: 0.2931\nEpoch [13/15], Loss: 0.2911\nEpoch [14/15], Loss: 0.2901\nEpoch [15/15], Loss: 0.2881\nAccuracy of the model on the test set: 87.27%\n","output_type":"stream"}]},{"cell_type":"code","source":"#LSTM and GLoVE\nimport numpy as np\n\ndef load_glove_embeddings(glove_file):\n    embeddings_index = {}\n    with open(glove_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            values = line.split()\n            word = values[0]\n            vector = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = vector\n    return embeddings_index","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:27:06.660120Z","iopub.execute_input":"2024-08-31T11:27:06.660636Z","iopub.status.idle":"2024-08-31T11:27:06.666750Z","shell.execute_reply.started":"2024-08-31T11:27:06.660599Z","shell.execute_reply":"2024-08-31T11:27:06.665685Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"glove_file = \"/kaggle/input/glove-6b/glove.6B.100d.txt\"  # Replace with the correct path to the GloVe file\nembeddings_index = load_glove_embeddings(glove_file)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:27:07.774006Z","iopub.execute_input":"2024-08-31T11:27:07.775037Z","iopub.status.idle":"2024-08-31T11:27:20.477175Z","shell.execute_reply.started":"2024-08-31T11:27:07.774993Z","shell.execute_reply":"2024-08-31T11:27:20.476354Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def text_to_glove(text, embeddings_index, vector_size):\n    words = word_tokenize(text)\n    word_vecs = [embeddings_index[word] for word in words if word in embeddings_index]\n    if len(word_vecs) == 0:\n        return torch.zeros(vector_size)\n    return torch.tensor(sum(word_vecs) / len(word_vecs))\n\ntrain_glove = torch.stack([text_to_glove(text, embeddings_index, 100) for text in train_df['cleaned_text']])\ntest_glove = torch.stack([text_to_glove(text, embeddings_index, 100) for text in test_df['cleaned_text']])","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:27:46.384794Z","iopub.execute_input":"2024-08-31T11:27:46.385671Z","iopub.status.idle":"2024-08-31T11:28:56.646822Z","shell.execute_reply.started":"2024-08-31T11:27:46.385633Z","shell.execute_reply":"2024-08-31T11:28:56.645966Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# 6. Custom Dataset for DataLoader\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]\n\ntrain_dataset = TextDataset(train_glove, torch.tensor(train_df['label'].values))\ntest_dataset = TextDataset(test_glove, torch.tensor(test_df['label'].values))\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:29:00.209914Z","iopub.execute_input":"2024-08-31T11:29:00.210619Z","iopub.status.idle":"2024-08-31T11:29:00.219311Z","shell.execute_reply.started":"2024-08-31T11:29:00.210581Z","shell.execute_reply":"2024-08-31T11:29:00.218266Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# 7. LSTM Model in PyTorch\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n        super(LSTMModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        out, _ = self.lstm(x.unsqueeze(1), (h0, c0))\n        out = self.fc(out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:29:08.676838Z","iopub.execute_input":"2024-08-31T11:29:08.677599Z","iopub.status.idle":"2024-08-31T11:29:08.685444Z","shell.execute_reply.started":"2024-08-31T11:29:08.677557Z","shell.execute_reply":"2024-08-31T11:29:08.684399Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Initialize model, criterion, and optimizer\ninput_size = 100  # GloVe vector size\nhidden_size = 50\noutput_size = 2  # Binary classification\n\nmodel = LSTMModel(input_size, hidden_size, output_size)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:29:14.741389Z","iopub.execute_input":"2024-08-31T11:29:14.741804Z","iopub.status.idle":"2024-08-31T11:29:14.748880Z","shell.execute_reply.started":"2024-08-31T11:29:14.741764Z","shell.execute_reply":"2024-08-31T11:29:14.747780Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# 8. Training Loop\ndef train_model(model, train_loader, criterion, optimizer, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs.float())\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:29:22.976287Z","iopub.execute_input":"2024-08-31T11:29:22.976691Z","iopub.status.idle":"2024-08-31T11:29:22.983143Z","shell.execute_reply.started":"2024-08-31T11:29:22.976655Z","shell.execute_reply":"2024-08-31T11:29:22.982045Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# 9. Testing Loop\ndef test_model(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            outputs = model(inputs.float())\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')\n\n# Train and test the model\ntrain_model(model, train_loader, criterion, optimizer, epochs=20\n           )\ntest_model(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:30:19.671617Z","iopub.execute_input":"2024-08-31T11:30:19.671997Z","iopub.status.idle":"2024-08-31T11:30:56.023375Z","shell.execute_reply.started":"2024-08-31T11:30:19.671962Z","shell.execute_reply":"2024-08-31T11:30:56.022419Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch [1/20], Loss: 0.4285\nEpoch [2/20], Loss: 0.4269\nEpoch [3/20], Loss: 0.4255\nEpoch [4/20], Loss: 0.4246\nEpoch [5/20], Loss: 0.4227\nEpoch [6/20], Loss: 0.4206\nEpoch [7/20], Loss: 0.4188\nEpoch [8/20], Loss: 0.4181\nEpoch [9/20], Loss: 0.4166\nEpoch [10/20], Loss: 0.4160\nEpoch [11/20], Loss: 0.4144\nEpoch [12/20], Loss: 0.4132\nEpoch [13/20], Loss: 0.4124\nEpoch [14/20], Loss: 0.4114\nEpoch [15/20], Loss: 0.4111\nEpoch [16/20], Loss: 0.4091\nEpoch [17/20], Loss: 0.4083\nEpoch [18/20], Loss: 0.4070\nEpoch [19/20], Loss: 0.4062\nEpoch [20/20], Loss: 0.4056\nAccuracy of the model on the test set: 80.76%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
